{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Data Preprocessing\n",
    "\n",
    "## Objective\n",
    "**WHY are we doing this preprocessing?**\n",
    "\n",
    "Based on findings from Data Understanding and EDA, we now prepare the data for machine learning. Each preprocessing step is **motivated by specific observations** from our analysis.\n",
    "\n",
    "### Preprocessing Goals:\n",
    "1. **Handle categorical variables** - Convert to numerical format for ML algorithms\n",
    "2. **Feature scaling** - Normalize features with different scales\n",
    "3. **Feature engineering** - Create new features based on domain knowledge\n",
    "4. **Train/Test split** - Properly separate data for unbiased evaluation\n",
    "5. **Address class imbalance** - If necessary based on model performance\n",
    "\n",
    "**Important:** We will explain **WHY** we make each preprocessing decision.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 1543 samples with 23 features\n",
      "\n",
      "Original columns: ['id', 'user_id', 'QoA_VLCresolution', 'QoA_VLCbitrate', 'QoA_VLCframerate', 'QoA_VLCdropped', 'QoA_VLCaudiorate', 'QoA_VLCaudioloss', 'QoA_BUFFERINGcount', 'QoA_BUFFERINGtime', 'QoS_type', 'QoS_operator', 'QoD_model', 'QoD_os-version', 'QoD_api-level', 'QoU_sex', 'QoU_age', 'QoU_Ustedy', 'QoF_begin', 'QoF_shift', 'QoF_audio', 'QoF_video', 'MOS']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv('../data/raw/pokemon.csv')\n",
    "print(f\"✓ Loaded {df.shape[0]} samples with {df.shape[1]} features\")\n",
    "print(f\"\\nOriginal columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Remove Unnecessary Features\n",
    "\n",
    "**WHY:** Some features don't contribute to prediction:\n",
    "- `id`: Just an identifier, no predictive power\n",
    "- `user_id`: User identity shouldn't directly predict MOS (unless we're doing personalization)\n",
    "- `QoD_model`, `QoD_os-version`: Too many unique values (high cardinality) - would need special encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing features:\n",
      "  - id: Just an identifier\n",
      "  - user_id: User identity (not using personalization)\n",
      "  - QoD_model: Too many unique values (high cardinality)\n",
      "  - QoD_os-version: Too many unique values (high cardinality)\n",
      "\n",
      "✓ Remaining features: 19\n",
      "Columns: ['QoA_VLCresolution', 'QoA_VLCbitrate', 'QoA_VLCframerate', 'QoA_VLCdropped', 'QoA_VLCaudiorate', 'QoA_VLCaudioloss', 'QoA_BUFFERINGcount', 'QoA_BUFFERINGtime', 'QoS_type', 'QoS_operator', 'QoD_api-level', 'QoU_sex', 'QoU_age', 'QoU_Ustedy', 'QoF_begin', 'QoF_shift', 'QoF_audio', 'QoF_video', 'MOS']\n"
     ]
    }
   ],
   "source": [
    "# Features to remove and why\n",
    "features_to_remove = {\n",
    "    'id': 'Just an identifier',\n",
    "    'user_id': 'User identity (not using personalization)',\n",
    "    'QoD_model': 'Too many unique values (high cardinality)',\n",
    "    'QoD_os-version': 'Too many unique values (high cardinality)'\n",
    "}\n",
    "\n",
    "print(\"Removing features:\")\n",
    "for feat, reason in features_to_remove.items():\n",
    "    if feat in df.columns:\n",
    "        print(f\"  - {feat}: {reason}\")\n",
    "        df = df.drop(columns=[feat])\n",
    "\n",
    "print(f\"\\n✓ Remaining features: {df.shape[1]}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle Categorical Variables\n",
    "\n",
    "**WHY:** Machine learning algorithms require numerical input. We have several categorical features that need encoding.\n",
    "\n",
    "### Encoding Strategy:\n",
    "- **Ordinal features** (with natural order): Use label encoding\n",
    "  - `QoS_type`: EDGE(1) < UMTS(2) < HSPA(3) < HSPAP(4) < LTE(5) ✓ Already encoded\n",
    "  - `QoU_Ustedy`: Education level (1-5) ✓ Already encoded\n",
    "  \n",
    "- **Nominal features** (no natural order): Use one-hot encoding\n",
    "  - `QoS_operator`: Network operators (no inherent order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current data types:\n",
      "QoA_VLCresolution       int64\n",
      "QoA_VLCbitrate        float64\n",
      "QoA_VLCframerate      float64\n",
      "QoA_VLCdropped          int64\n",
      "QoA_VLCaudiorate      float64\n",
      "QoA_VLCaudioloss        int64\n",
      "QoA_BUFFERINGcount      int64\n",
      "QoA_BUFFERINGtime       int64\n",
      "QoS_type                int64\n",
      "QoS_operator            int64\n",
      "QoD_api-level           int64\n",
      "QoU_sex                 int64\n",
      "QoU_age                 int64\n",
      "QoU_Ustedy              int64\n",
      "QoF_begin               int64\n",
      "QoF_shift               int64\n",
      "QoF_audio               int64\n",
      "QoF_video               int64\n",
      "MOS                     int64\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "Categorical Features Analysis:\n",
      "============================================================\n",
      "\n",
      "QoS_operator:\n",
      "  Unique values: 4\n",
      "  Values: [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Current data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Identify categorical features that need encoding\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Categorical Features Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "categorical_cols = ['QoS_operator']  # Nominal feature\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Unique values: {df[col].nunique()}\")\n",
    "        print(f\"  Values: {sorted(df[col].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying One-Hot Encoding to QoS_operator...\n",
      "✓ One-hot encoding complete\n",
      "New columns: ['Operator_SFR', 'Operator_BOUYEGUES', 'Operator_ORANGE', 'Operator_FREE']\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode QoS_operator\n",
    "print(\"\\nApplying One-Hot Encoding to QoS_operator...\")\n",
    "\n",
    "# Create mapping for better column names\n",
    "operator_mapping = {1: 'SFR', 2: 'BOUYEGUES', 3: 'ORANGE', 4: 'FREE'}\n",
    "\n",
    "# One-hot encode\n",
    "operator_encoded = pd.get_dummies(df['QoS_operator'], prefix='Operator')\n",
    "operator_encoded.columns = [f'Operator_{operator_mapping.get(int(col.split(\"_\")[1]), col.split(\"_\")[1])}' \n",
    "                            for col in operator_encoded.columns]\n",
    "\n",
    "# Drop original and add encoded\n",
    "df = df.drop(columns=['QoS_operator'])\n",
    "df = pd.concat([df, operator_encoded], axis=1)\n",
    "\n",
    "print(f\"✓ One-hot encoding complete\")\n",
    "print(f\"New columns: {[col for col in df.columns if 'Operator' in col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "**WHY:** Based on EDA insights, we can create new features that might better capture QoE patterns.\n",
    "\n",
    "### New Features to Create:\n",
    "1. **Buffering_Severity**: Combines buffering count and time\n",
    "2. **Quality_Score**: Composite score from bitrate, framerate, resolution\n",
    "3. **Network_Generation**: Grouped network types (2G, 3G, 4G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating engineered features...\n",
      "\n",
      "✓ Buffering_Severity: count × time / 1000\n",
      "✓ Network_Generation: Grouped by technology generation (2G/3G/4G)\n",
      "✓ Video_Quality_Index: Weighted combination of bitrate, framerate, resolution\n",
      "✓ Audio_Quality: Audio rate adjusted by loss percentage\n",
      "\n",
      "New feature count: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating engineered features...\\n\")\n",
    "\n",
    "# 1. Buffering Severity (normalized)\n",
    "df['Buffering_Severity'] = (\n",
    "    df['QoA_BUFFERINGcount'] * df['QoA_BUFFERINGtime'] / 1000\n",
    ").fillna(0)\n",
    "print(\"✓ Buffering_Severity: count × time / 1000\")\n",
    "\n",
    "# 2. Network Generation\n",
    "network_gen_mapping = {\n",
    "    1: 2,  # EDGE -> 2G\n",
    "    2: 3,  # UMTS -> 3G\n",
    "    3: 3,  # HSPA -> 3G\n",
    "    4: 3,  # HSPAP -> 3G\n",
    "    5: 4   # LTE -> 4G\n",
    "}\n",
    "df['Network_Generation'] = df['QoS_type'].map(network_gen_mapping)\n",
    "print(\"✓ Network_Generation: Grouped by technology generation (2G/3G/4G)\")\n",
    "\n",
    "# 3. Video Quality Index (normalized)\n",
    "# Higher bitrate + higher framerate + higher resolution = better quality\n",
    "df['Video_Quality_Index'] = (\n",
    "    (df['QoA_VLCbitrate'] / df['QoA_VLCbitrate'].max()) * 0.4 +\n",
    "    (df['QoA_VLCframerate'] / df['QoA_VLCframerate'].max()) * 0.3 +\n",
    "    (df['QoA_VLCresolution'] / df['QoA_VLCresolution'].max()) * 0.3\n",
    ")\n",
    "print(\"✓ Video_Quality_Index: Weighted combination of bitrate, framerate, resolution\")\n",
    "\n",
    "# 4. Audio Quality (combine audio rate and loss)\n",
    "df['Audio_Quality'] = df['QoA_VLCaudiorate'] * (1 - df['QoA_VLCaudioloss'] / 100)\n",
    "print(\"✓ Audio_Quality: Audio rate adjusted by loss percentage\")\n",
    "\n",
    "print(f\"\\nNew feature count: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "\n",
    "**WHY:** We must separate data BEFORE any scaling to prevent data leakage.\n",
    "\n",
    "### Split Strategy:\n",
    "- **80/20 split** - Standard practice\n",
    "- **Stratified** - Maintain MOS class distribution (important due to class imbalance)\n",
    "- **Random state** - For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1543, 25)\n",
      "Target shape: (1543,)\n",
      "\n",
      "Target distribution:\n",
      "MOS\n",
      "1     93\n",
      "2    118\n",
      "3    246\n",
      "4    784\n",
      "5    302\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Train set: 1234 samples\n",
      "✓ Test set: 309 samples\n",
      "\n",
      "MOS distribution in train set:\n",
      "MOS\n",
      "1    0.060\n",
      "2    0.076\n",
      "3    0.160\n",
      "4    0.508\n",
      "5    0.196\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "MOS distribution in test set:\n",
      "MOS\n",
      "1    0.061\n",
      "2    0.078\n",
      "3    0.159\n",
      "4    0.508\n",
      "5    0.194\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['MOS'])\n",
    "y = df['MOS']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts().sort_index())\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"✓ Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\nMOS distribution in train set:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index().round(3))\n",
    "print(\"\\nMOS distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True).sort_index().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Scaling\n",
    "\n",
    "**WHY:** Features have very different scales (e.g., bitrate ~500, age ~25). Many ML algorithms (SVM, KNN, Neural Nets) perform better with scaled features.\n",
    "\n",
    "**IMPORTANT:** We fit the scaler on training data only, then transform both train and test to prevent data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Features scaled using StandardScaler\n",
      "\n",
      "Scaled features - Train: (1234, 25)\n",
      "Scaled features - Test: (309, 25)\n",
      "\n",
      "Before scaling (sample):\n",
      "     QoA_VLCbitrate  QoU_age  QoA_BUFFERINGtime\n",
      "604       393.35184       29               2416\n",
      "117       391.83496       28               1413\n",
      "888       185.53412       25               2998\n",
      "\n",
      "After scaling (same sample):\n",
      "     QoA_VLCbitrate   QoU_age  QoA_BUFFERINGtime\n",
      "604       -0.377626 -0.009995          -0.240226\n",
      "117       -0.382027 -0.137142          -0.305573\n",
      "888       -0.980521 -0.518582          -0.202308\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data only!\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Use fitted scaler\n",
    "\n",
    "# Convert back to DataFrame for convenience\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"✓ Features scaled using StandardScaler\")\n",
    "print(f\"\\nScaled features - Train: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled features - Test: {X_test_scaled.shape}\")\n",
    "\n",
    "# Show scaling effect\n",
    "print(\"\\nBefore scaling (sample):\")\n",
    "print(X_train[['QoA_VLCbitrate', 'QoU_age', 'QoA_BUFFERINGtime']].head(3))\n",
    "print(\"\\nAfter scaling (same sample):\")\n",
    "print(X_train_scaled[['QoA_VLCbitrate', 'QoU_age', 'QoA_BUFFERINGtime']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Preprocessed Data\n",
    "\n",
    "**WHY:** Save processed data and scaler for:\n",
    "- Reproducibility\n",
    "- Use in modeling notebooks\n",
    "- Future predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved preprocessed data:\n",
      "  - X_train_scaled.csv, X_test_scaled.csv\n",
      "  - X_train.csv, X_test.csv (unscaled)\n",
      "  - y_train.csv, y_test.csv\n",
      "  - scaler.pkl\n",
      "  - feature_names.txt\n"
     ]
    }
   ],
   "source": [
    "# Save processed datasets\n",
    "X_train_scaled.to_csv('../data/processed/X_train_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv('../data/processed/X_test_scaled.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "\n",
    "# Save unscaled versions too (for tree-based models)\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "\n",
    "# Save scaler\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save feature names\n",
    "feature_names = list(X_train.columns)\n",
    "with open('../data/processed/feature_names.txt', 'w') as f:\n",
    "    f.write('\\n'.join(feature_names))\n",
    "\n",
    "print(\"✓ Saved preprocessed data:\")\n",
    "print(\"  - X_train_scaled.csv, X_test_scaled.csv\")\n",
    "print(\"  - X_train.csv, X_test.csv (unscaled)\")\n",
    "print(\"  - y_train.csv, y_test.csv\")\n",
    "print(\"  - scaler.pkl\")\n",
    "print(\"  - feature_names.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preprocessing Summary\n",
    "\n",
    "### What We Did:\n",
    "\n",
    "1. **Feature Removal:**\n",
    "   - Removed: id, user_id, QoD_model, QoD_os-version\n",
    "   - Why: No predictive value or too high cardinality\n",
    "\n",
    "2. **Encoding:**\n",
    "   - One-hot encoded: QoS_operator\n",
    "   - Kept as-is: Already encoded ordinal features\n",
    "\n",
    "3. **Feature Engineering:**\n",
    "   - Created: Buffering_Severity, Network_Generation, Video_Quality_Index, Audio_Quality\n",
    "   - Why: Capture domain knowledge about QoE factors\n",
    "\n",
    "4. **Train/Test Split:**\n",
    "   - 80/20 split with stratification\n",
    "   - Why: Maintain class distribution, enable unbiased evaluation\n",
    "\n",
    "5. **Scaling:**\n",
    "   - StandardScaler (mean=0, std=1)\n",
    "   - Why: Different feature scales, better for many algorithms\n",
    "   - Important: Fitted on train only!\n",
    "\n",
    "### Critical Assessment:\n",
    "\n",
    "**Limitations:**\n",
    "- Removed high-cardinality features (device model) - might lose information\n",
    "- Feature engineering based on assumptions - may not be optimal\n",
    "- Class imbalance still present - may address during modeling if needed\n",
    "\n",
    "**Assumptions:**\n",
    "- Linear scaling appropriate for all features\n",
    "- One-hot encoding for operator won't cause multicollinearity issues\n",
    "- Engineered features capture meaningful patterns\n",
    "\n",
    "### Next Steps:\n",
    "1. Baseline model creation\n",
    "2. Model comparison and selection\n",
    "3. Hyperparameter tuning\n",
    "4. Address class imbalance if necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
